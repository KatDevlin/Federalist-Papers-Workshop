---
title: "FederalistPapers-part3"
author: "Ryan Wesslen"
date: "October 2, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Step 10: Rerun preparation steps.

Let's rerun our initial steps. If you are manually running the chunks, you may not need to rerun this process.

```{r}
setwd("~/Dropbox/Federalist-Papers-Workshop")  #Linux
#setwd("C:/Users/rwesslen/Dropbox/Federalist-Papers-Workshop") #Windows

papers <- read.csv("./data/federalist.csv", stringsAsFactors = F)

#		train/test: limit to Hamilton/Mad documents (drop Jay and Ham&Madison papers)
train <- which(papers$auth=="HAMILTON" | papers$auth=="MADISON")
length(train)	# 65

test <- which(papers$auth=="DISPUTED")
length(test)	# 12

library(quanteda)

# remove "To the People of the State of New York <l>"
papers$text <- substring(papers$text,45)

# remove html tags
tags <- c("<c>","<p>","<S>","<l>","<q>","<d>","<Q>")
for (i in tags){
  papers$text <- gsub(i," ",papers$text)
}

# build the corpus
myCorpus <- corpus(papers$text)

# add in the attributes about the papers (number, author, train/test flag)
docvars(myCorpus, "Number") <- papers$number
docvars(myCorpus, "Author") <- papers$author

# summarize the documents
summary(myCorpus, 5)

stopWords <- c("will","one","two","may","less", "well","might","without","small","single", "several","however","must","number","part","upon","consider","particular","place","true","shall","often","former","latter","want","can","everything","every","different","either","yet","made","now","publius","therefore","first","second","third","though","another","found","within","even","far","just","also","said","ever","three","four","still","little","federal","members","national","union","united","general","government","governments","power","powers","state","states","people","constitution","constitutions")

myDfm <- dfm(myCorpus, ignoredFeatures = c(stopwords("english"),stopWords), stem = F, ngrams = c(1,3))

myDfm <- trim(myDfm, minCount=10, minDoc=5)
```

## Step 11: Run LDA (Topic Modeling)

In this exercise, we're going to run latent Dirichlet allocation (LDA), which is the workhorse topic model.

```{r, results = 'hide'}
# we now export to a format that we can run the topic model with
dtm <- convert(myDfm, to="topicmodels")
```

```{r}
# install.packages("topicmodels")
library(topicmodels)

#Set parameters for Gibbs sampling
burnin <- 1000
iter <- 4000
thin <- 100
seed <- 40

#Number of Topics
k <- 20

#Run LDA using Gibbs sampling
lda <-LDA(dtm,k, method='Gibbs', 
             control=list(seed = seed, burnin = burnin, iter = iter, thin = thin))
```

Before running we need to run a helper function (I'll explain in a second):

```{r}
topicmodels_json_ldavis <- function(fitted, dfm, dtm){
  # Required packages
  library(topicmodels)
  library(dplyr)
  library(stringi)
  library(quanteda)
  library(LDAvis)
  library(tm)
  
  # Find required quantities
  phi <- posterior(fitted)$terms %>% as.matrix
  theta <- posterior(fitted)$topics %>% as.matrix
  vocab <- colnames(phi)
  
  doc_length <- ntoken(dfm[rownames(dtm)])
  
  temp_frequency <- inspect(dtm)
  freq_matrix <- data.frame(ST = colnames(temp_frequency),
                            Freq = colSums(temp_frequency))
  rm(temp_frequency)
  
  # Convert to json
  json_lda <- LDAvis::createJSON(phi = phi, theta = theta,
                                 vocab = vocab,
                                 doc.length = doc_length,
                                 term.frequency = freq_matrix$Freq)
  
  return(json_lda)
}
```

Let's explore the results using the `terms` function.

```{r, results = 'hide'}
#Create Json for LDAVis
json <- topicmodels_json_ldavis(lda, myCorpus, dtm)
new.order <- RJSONIO::fromJSON(json)$topic.order
```

```{r}
term <- terms(lda, 10)
term <- term[,new.order]
colnames(term) <- paste("Topic",1:20)
term
```

We can save the topic names as the top 10 words per topic:

```{r}
topic.names <- apply(term, MARGIN = 2, paste, collapse = ", ")
```

Last, we can use the LDAvis package to create a Shiny app for our results:

```{r, eval=FALSE}
serVis(json, out.dir = 'federalist', open.browser = TRUE)
```

To view this app, [click here](https://htmlpreview.github.io/?https://github.com/wesslen/Federalist-Papers-Workshop/blob/master/federalist/index.html).

## Step 12: Topic Labeling

```{r}
# Name (label) the topics
names <- c("Legalese","War/National Security","Enlightenment","House Term Period","Military & Army","Judicial Branch","Public Opinion","Republican Majority","Clauses","Known Issues","Senate","Conduct of Man","Revenue","Local Rights","Convention","Checks & Balances","Foreign Assets","History","Property Rights","States Rights")

## Topic Cluster heatmaps

# to get topic probabilities per document
postlist <- posterior(lda)
probtopics <- data.frame(postlist$topics[,new.order])
heat_data <- as.matrix(probtopics)

colnames(heat_data) <- names
levels(papers$author)[2] <- "BOTH"
levels(papers$author)[3] <- "???"
name <- paste(papers$number,". ",papers$author)
```

## Step 13: Topic Visualization per Paper

```{r, fig.width=6, fig.height=9}
library(d3heatmap)

# Cluster topics (rows)
d3heatmap(data.frame(heat_data), dendrogram = "col", scale = "col", 
           labRow = name, cexRow=.8, cexCol=.8, k_row = 5)

# Cluster topics (rows) and papers (columns)
d3heatmap(data.frame(heat_data), scale = "col", 
            labRow = name, cexRow=.8, cexCol=.8, k_row = 5)
```

## Advanced Topics

What is the right number of topics to use?

* Is it better that topics are interpretable?

* Or is it better that topics are predictive?

[Chang et al (2009)](https://www.cs.princeton.edu/~blei/papers/ChangBoyd-GraberWangGerrishBlei2009a.pdf) finds that these two competing objectives may end up with conflicting results: "Topic models which perform better on held-out likelihood may infer
less semantically meaningful topics".

If your answer is the more interpretable topics, then you can simply alter assumptions and rerun until you're satisfied. 

If instead you want the most predictive, you will need the `cvTools` package (not part of the original libraries) and to run the following script (note the user-defined functions in the `functions.R` file):

```{r, results='hide'}
# install.packages("cvTools")
require(cvTools)
source("../part3/functions.R")

K <- c(10, 20, 35, 50, 75, 100)

results <- list()

i = 1
for (k in K){
    cat("\n\n\n##########\n ", k, "topics", "\n")
    res <- cvLDA(k, dtm)
    results[[i]] <- res
    i = i + 1
}
```

```{r}
topicPlots(results,K)
```

Another exercise you can consider is to measure is the correlation between the topics.

One way to approach this is to visualize the correlation between topic-word probabilities. Check out this [blog post](https://wesslen.github.io/text%20mining/topic-networks/) for more details.

For this, I create another user-defined function called `corrPlot` in the `functions.R` file.

```{r}
probterms <- data.frame(t(postlist$terms[new.order,]))
corrPlot(probterms, thres = 0.08)
```